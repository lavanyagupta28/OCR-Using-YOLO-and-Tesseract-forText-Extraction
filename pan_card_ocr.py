# -*- coding: utf-8 -*-
"""pan_card_ocr.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18OK2HSBu0J3Y084TuqeHEqpkDfOGX3Qb
"""

from google.colab import drive
drive.mount('/content/gdrive')
!ln -s /content/gdrive/My\ Drive/ /mydrive
!ls /mydrive

!unzip /content/gdrive/MyDrive/yolo_custom_training/ocr.v6i.darknet.zip -d /content/gdrive/MyDrive/yolo_custom_training/images

!mkdir -p /content/gdrive/MyDrive/yolo_custom_training/darknet

import os
print(os.getcwd())

!chmod +x+u+w /content/gdrive/MyDrive/yolo_custom_training

!git clone 'https://github.com/AlexeyAB/darknet.git' '/content/gdrive/MyDrive/yolo_custom_training/darknet'

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/gdrive/MyDrive/yolo_custom_training/darknet
!sed -i 's/OPENCV=0/OPENCV=1/' Makefile
!sed -i 's/GPU=0/GPU=1/' Makefile
!sed -i 's/CUDNN=0/CUDNN=1/' Makefile
!make clean
!make

!cp cfg/yolov3.cfg cfg/yolov3_custom_training.cfg

import os
train_images_dir = '/content/gdrive/MyDrive/yolo_custom_training/images/train'
test_images_dir = '/content/gdrive/MyDrive/yolo_custom_training/images/test'

test_txt_path =   '/content/gdrive/MyDrive/yolo_custom_training/images/test.txt'
train_txt_path = '/content/gdrive/MyDrive/yolo_custom_training/images/train.txt'

def generate_file_list(images_dir, output_file):
  with open(output_file, 'w') as f:
    for filename in os.listdir(images_dir):
      if filename.endswith('.jpg'):
        abs_path = os.path.join(images_dir, filename)
        f.write(abs_path + '\n')

generate_file_list(train_images_dir, train_txt_path)
generate_file_list(test_images_dir, test_txt_path)

!wget -P '/content/gdrive/MyDrive/yolo_custom_training/custom_weight' 'https://pjreddie.com/media/files/darknet53.conv.74'

!chmod +x+u+w /content/gdrive/MyDrive/yolo_custom_training

print(os.getcwd())
os.chdir('/content/gdrive/MyDrive/yolo_custom_training')

!/content/gdrive/MyDrive/yolo_custom_training/darknet/darknet detector train /content/gdrive/MyDrive/yolo_custom_training/images/path_data.data /content/gdrive/MyDrive/yolo_custom_training/darknet/cfg/yolov3_custom_training.cfg /content/gdrive/MyDrive/yolo_custom_training/custom_weight/darknet53.conv.74 -dont_show -show_imgs -gpus 0

!sudo apt install tesseract-ocr

!pip install pytesseract openpyxl pillow

!which tesseract

import cv2
import pytesseract
import numpy as np
from openpyxl import Workbook
import os



test_folder = '/content/gdrive/MyDrive/yolo_custom_training/images/test'
labels_file = '/content/gdrive/MyDrive/yolo_custom_training/images/classes.names'
output_folder = '/content/gdrive/MyDrive/yolo_custom_training/images/output2'
cfg_file = '/content/gdrive/MyDrive/yolo_custom_training/darknet/cfg/yolov3_custom_training.cfg'
weights = '/content/gdrive/MyDrive/yolo_custom_training/images/backup/yolov3_custom_training_final.weights'
output_excel = '/content/gdrive/MyDrive/yolo_custom_training/images/ouput.xlsx'
CONFIDENCE_THRESHOLD = 0.4

# Initialize Tesseract
pytesseract.pytesseract.tesseract_cmd = '/usr/bin/tesseract'

# YOLOv3 class labels
classes = open(labels_file).read().strip().split("\n")

# Load YOLOv3 model
net = cv2.dnn.readNetFromDarknet(cfg_file, weights)
ln = net.getLayerNames()
ln = [ln[i - 1] for i in net.getUnconnectedOutLayers()]

# Initialize Excel workbook
workbook = Workbook()
sheet = workbook.active
sheet.title = "Extracted Text"

# Add headers
sheet.append(["Date", "FathersName", "Name", "Pan"])

# Process each image
for image_file in os.listdir(test_folder):
    input_path = os.path.join(test_folder, image_file)

    if not input_path.lower().endswith(('.jpg', '.jpeg', '.png')):
        continue

    print(f"Processing {image_file}...")
    image = cv2.imread(input_path)
    (H, W) = image.shape[:2]

    # YOLO preprocessing
    blob = cv2.dnn.blobFromImage(image, 1 / 255.0, (416, 416), swapRB=True, crop=False)
    net.setInput(blob)
    layerOutputs = net.forward(ln)

    # Initialize lists
    boxes = []
    confidences = []
    classIDs = []

    # Process detections
    for output in layerOutputs:
        for detection in output:
            scores = detection[5:]
            classID = np.argmax(scores)
            confidence = scores[classID]

            if confidence > CONFIDENCE_THRESHOLD:
                box = detection[0:4] * np.array([W, H, W, H])
                (centerX, centerY, width, height) = box.astype("int")

                x = int(centerX - (width / 2))
                y = int(centerY - (height / 2))

                boxes.append([x, y, int(width), int(height)])
                confidences.append(float(confidence))
                classIDs.append(classID)

    # Apply Non-Maxima Suppression
    idxs = cv2.dnn.NMSBoxes(boxes, confidences, CONFIDENCE_THRESHOLD, CONFIDENCE_THRESHOLD)

    row_data = ["", "", "", ""]  # For Date, FathersName, Name, Pan

    if len(idxs) > 0:
        for i in idxs.flatten():
            x, y, w, h = boxes[i]
            roi = image[y:y + h, x:x + w]

            try:
                # Perform OCR on the cropped ROI
                text = pytesseract.image_to_string(roi).strip()
            except Exception as e:
                text = f"[ERROR] {str(e)}"

            # Assign detected text to the correct column (based on class ID or heuristic)
            if classes[classIDs[i]].lower() == "dob":
                row_data[0] = text
            elif classes[classIDs[i]].lower() == "father":
                row_data[1] = text
            elif classes[classIDs[i]].lower() == "name":
                row_data[2] = text
            elif classes[classIDs[i]].lower() == "pan":
                row_data[3] = text

            # Optional: Draw bounding boxes for debugging
            color = (0, 255, 0)
            cv2.rectangle(image, (x, y), (x + w, y + h), color, 2)
            cv2.putText(image, text, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)

    # Add row data to the Excel file
    sheet.append(row_data)

    # Save the processed image for reference (optional)
    output_image_path = os.path.join(test_folder, f"output_{image_file}")
    cv2.imwrite(output_image_path, image)

# Save Excel workbook
workbook.save(output_excel)
print(f"[INFO] Data written to {output_excel}")



